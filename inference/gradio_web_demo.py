"""
This script demonstrates how to generate an image using the CogView4-6B model within the Hugging Face Space interface. Simply interact with the Gradio interface hosted on Hugging Face CogView4 Demo at [CogView4-6B Hugging Face Space](https://huggingface.co/spaces/THUDM-HF-SPACE/CogView4)

Running the Script:
To run the script, use the following command with appropriate arguments:

```bash
OPENAI_API_KEY="your ZhipuAI API keys" OPENAI_BASE_URL="https://open.bigmodel.cn/api/paas/v4" python gradio_web_demo.py
```

We use [glm-4-plus](https://bigmodel.cn/dev/howuse/glm-4) as the large model for prompt refinement. You can also choose other large models, such as GPT-4o, for refinement.â€
"""

import os
import re
import threading
import time
from datetime import datetime, timedelta

import gradio as gr
import random
from diffusers import CogView4Pipeline
from diffusers.models import AutoencoderKL, CogView4Transformer2DModel
import torch
from openai import OpenAI

from transformers import GlmModel
from torchao.quantization import quantize_, int8_weight_only
import gc

os.environ["OPENAI_BASE_URL"]="https://open.bigmodel.cn/api/paas/v4"
mode = os.environ.get("MODE", "1")

total_vram_in_gb = torch.cuda.get_device_properties(0).total_memory / 1073741824
print(f'\033[32mCUDAç‰ˆæœ¬ï¼š{torch.version.cuda}\033[0m')
print(f'\033[32mPytorchç‰ˆæœ¬ï¼š{torch.__version__}\033[0m')
print(f'\033[32mæ˜¾å¡å‹å·ï¼š{torch.cuda.get_device_name()}\033[0m')
print(f'\033[32mæ˜¾å­˜å¤§å°ï¼š{total_vram_in_gb:.2f}GB\033[0m')
if torch.cuda.get_device_capability()[0] >= 8:
    print(f'\033[32mæ”¯æŒBF16\033[0m')
    dtype = torch.bfloat16
else:
    print(f'\033[32mä¸æ”¯æŒBF16ï¼Œä½¿ç”¨FP16\033[0m')
    dtype = torch.float16
device = "cuda" if torch.cuda.is_available() else "cpu"

model_path = "THUDM/CogView4-6B"

text_encoder = None
transformer = None
if mode in ["1","2"]:
    # æ³¨æ„ï¼šå®é™…é‡åŒ–éœ€è¦æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒé‡åŒ–
    from utils import quantize_, int8_weight_only
    text_encoder = GlmModel.from_pretrained(model_path, subfolder="text_encoder", torch_dtype=dtype)
    transformer = CogView4Transformer2DModel.from_pretrained(model_path, subfolder="transformer", torch_dtype=dtype)
    quantize_(text_encoder, int8_weight_only())
    quantize_(transformer, int8_weight_only())

# åŠ è½½å®Œæ•´pipeline
pipe = CogView4Pipeline.from_pretrained(
    model_path,
    text_encoder=text_encoder,  # è‡ªåŠ¨åŠ è½½é»˜è®¤ç»„ä»¶ï¼Œé™¤ééœ€è¦è‡ªå®šä¹‰
    transformer=transformer,
    torch_dtype=dtype,
).to(device)

if mode in ["1","3"]:
    pipe.enable_model_cpu_offload()
pipe.vae.enable_slicing()
pipe.vae.enable_tiling()


def clean_string(s):
    s = s.replace("\n", " ")
    s = s.strip()
    s = re.sub(r"\s{2,}", " ", s)
    return s


def convert_prompt(
    prompt: str,
    key: str,
    retry_times: int = 5,
) -> str:
    os.environ["OPENAI_API_KEY"]=key
    if not key:
        return prompt
    client = OpenAI()
    prompt = clean_string(prompt)
    for i in range(retry_times):
        try:
            response = client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": 'You are a bilingual image description assistant that works with an image generation bot.  You work with an assistant bot that will draw anything you say . \n    For example ,For example, outputting "a beautiful morning in the woods with the sun peaking through the trees" or "é˜³å…‰é€è¿‡æ ‘æ—çš„ç¾ä¸½æ¸…æ™¨" will trigger your partner bot to output an image of a forest morning, as described . \n    You will be prompted by people looking to create detailed , amazing images . The way to accomplish this is to take their short prompts and make them extremely detailed and descriptive . \n    There are a few rules to follow : \n    - Input can be in Chinese or English. If input is in English, prompt should be written in English. If input is in Chinese, prompt should be written in Chinese.\n    - You will only ever output a single image description per user request .\n    - Image descriptions must be detailed and specific, including keyword categories such as subject, medium, style, additional details, color, and lighting. \n    - When generating descriptions, focus on portraying the visual elements rather than delving into abstract psychological and emotional aspects. Provide clear and concise details that vividly depict the scene and its composition, capturing the tangible elements that make up the setting.\n    - Do not provide the process and explanation, just return the modified description . \n    ',
                    },
                    {
                        "role": "user",
                        "content": 'Create an imaginative image descriptive caption for the user input : "An anime girl stands amidst a dense flower bush."',
                    },
                    {
                        "role": "assistant",
                        "content": "This image is a beautifully crafted digital illustration in an anime style. It features Suzuran, a character from the video game Arknights. She stands gracefully amidst a picturesque meadow with lush green grass and scattered wildflowers that gently sway in the breeze. Her attire includes a detailed outfit with layered ruffles and intricate fastenings, reflecting both elegance and functionality typical of the game's aesthetic. Suzuran holds a small bouquet of flowers delicately in her hands, adding to the serene atmosphere.\n\nProminent fox ears extend from her head, signifying her animal spirit form or persona within the game. The background showcases rolling hills covered in dense foliage under a brilliant blue sky dotted with fluffy white clouds. Golden leaves float whimsically through the air, enhancing the magical quality of the scene. A distant building partially obscured by vegetation hints at human presence without detracting from the natural beauty surrounding Suzuran. Overall, this artwork captures a moment of tranquility and charm, embodying the essence of the character and the enchanting world she inhabits.",
                    },
                    {
                        "role": "user",
                        "content": 'Create an imaginative image descriptive caption for the user input : "Draw a bright convertible car with a sense of artistic design."',
                    },
                    {
                        "role": "assistant",
                        "content": 'The image showcases a meticulously crafted Delahaye 135 M.S. Special Roadster from 1937 in a highly polished and realistic rendering style that highlights its luxurious design and impeccable details. The car\'s body is an elegant deep brown with a glossy finish, exuding sophistication and timeless beauty. Its aerodynamic, streamlined shape features smooth curves accentuated by chrome detailing on the fenders and running boards. The front grille has three prominent circular headlights, adding to its classic charm while the dual exhaust pipes are tastefully integrated into the rear fenders.\n\nThe open cockpit area reveals sumptuous tan leather seats, emphasizing both comfort and elegance for the driver and passenger. The vehicleâ€™s number plate reads "MB 175". Photographed against a dark gradient background, the focus remains solely on this automotive masterpiece, allowing viewers to appreciate every intricate detail without distraction. This image captures not just a car but a piece of art, reflecting the luxury and craftsmanship emblematic of pre-war European automobiles.',
                    },
                    {
                        "role": "user",
                        "content": 'Create an imaginative image descriptive caption for the user input : "ç”»ä¸€ä¸ªç™½å‘ã€ç¥æƒ…å¿§éƒçš„åŠ¨æ¼«å¥³å­©ï¼Œæ‰‹é‡Œæ‹¿ç€ä¸€æ”¯é¦™çƒŸ"',
                    },
                    {
                        "role": "assistant",
                        "content": "è¿™å¹…å›¾åƒæ˜¯ä¸€å¹…åŠ¨æ¼«é£æ ¼çš„æ’ç”»ï¼Œç”»ä¸­æç»˜äº†ä¸€ä½é•¿å‘é£˜é€¸çš„ç™½å‘å¥³å­©ã€‚å¥¹ç¥æƒ…å¿§éƒï¼ŒåŒçœ¼ä½å‚ï¼Œè„¸ä¸Šå¸¦ç€å¾®å¾®çš„æ„å®¹ã€‚å¥³å­©ç©¿ç€æµ…è‰²å¤–å¥—ï¼Œé‡Œé¢æ­é…æ·±è‰²è¡¬è¡«å’Œé¢†å¸¦ï¼Œå¢æ·»äº†å¥¹æ²‰é™å´æ—¶å°šçš„å¤–è¡¨ã€‚å¥¹çš„æ‰‹é è¿‘å˜´è¾¹ï¼Œä¼¼ä¹åœ¨æ‹¿ç€ä¸€æ”¯é¦™çƒŸï¼Œç”»ä½œçš„è¯´æ˜ä¹Ÿè¡¨ç¤ºå¥¹åœ¨å¸çƒŸã€‚èƒŒæ™¯æç»˜äº†ä¸€ä¸ªå†¬å­£çš„åŸå¸‚åœºæ™¯ï¼Œåœ°é¢å’Œå»ºç­‘ç‰©ä¸Šè¦†ç›–ç€ç§¯é›ªã€‚å‡ æ ªç¨€ç–çš„æ¤ç‰©ä»é›ªåœ°ä¸­æ¢å‡ºï¼Œè¡—è¾¹åœç€ä¸€è¾†è½¦ï¼Œä¼¼ä¹æ˜¯ç©ºè¡è¡çš„è¡—é“ï¼Œå¢å¼ºäº†åœºæ™¯çš„è’å‡‰æ°›å›´ã€‚è¿™å¹…ä½œå“æ•´ä½“é£æ ¼ç»†è‡´ç²¾ç¾ï¼Œå…¸å‹çš„ç°ä»£åŠ¨æ¼«æ’ç”»é£æ ¼ï¼Œæ—¢æ•æ‰äº†è§’è‰²çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œä¹Ÿå‘ˆç°äº†å‘¨å›´ç¯å¢ƒçš„é™è°§æ°›å›´",
                    },
                    {
                        "role": "user",
                        "content": 'Create an imaginative image descriptive caption for the user input : "ä¸€å¼ çº¢è‰²çš„æµ·æŠ¥ï¼Œä¸­é—´å†™æœ‰â€œå¼€é—¨å¤§å‰â€"',
                    },
                    {
                        "role": "assistant",
                        "content": "è¿™å¼ å›¾ç‰‡é‡‡ç”¨äº†æµ·æŠ¥é£æ ¼ï¼Œè‰²å½©é²œè‰³ï¼Œä¸»è¦ä»¥çº¢è‰²å’Œé‡‘è‰²ä¸ºä¸»ï¼Œå¯“æ„å‰ç¥¥å¦‚æ„ã€‚åœ¨ç”»é¢çš„æ­£ä¸­é—´æ˜¯ä¸€å—çº¢è‰²çš„å¤§åŒ¾ï¼Œä¸Šé¢ç”¨ç™½è‰²å¤§å­—å†™ç€â€œå¼€é—¨å¤§å‰â€ï¼Œå››è§’ç‚¹ç¼€ç€é‡‘è‰²çš„è£…é¥°å›¾æ¡ˆï¼Œæ˜¾å¾—æ ¼å¤–å–œåº†ã€‚åŒ¾é¢ä¸Šæ–¹æ‚¬æŒ‚ç€ä¸€å¯¹çº¢è‰²çš„ç¯ç¬¼ï¼Œå¢æ·»äº†èŠ‚æ—¥çš„æ°”æ°›ã€‚èƒŒæ™¯å·¦å³ä¸¤ä¾§æ˜¯ä¼ ç»Ÿçš„ç»¿è‰²ä¸­å¼å»ºç­‘ï¼Œå±‹é¡¶å‘ˆç°å‡ºå…¸å‹çš„é£æªç¿˜è§’è®¾è®¡ã€‚åº•éƒ¨æœ‰ç¥¥äº‘æœµæœµå’Œå¯çˆ±çš„å¡é€šç¦è¢‹ï¼Œè±¡å¾ç€å¥½è¿ç¦æ°”æ»¡æ»¡ã€‚æ•´å¼ æµ·æŠ¥ä¼ è¾¾å‡ºæµ“åšçš„èŠ‚æ—¥æ°›å›´ã€‚",
                    },
                    {
                        "role": "user",
                        "content": f"Create an imaginative image descriptive caption for the user input : {prompt}",
                    },
                ],
                model="glm-4-flash",
                temperature=0.01,
                top_p=0.7,
                stream=False,
                max_tokens=300,
            )
            prompt = response.choices[0].message.content
            if prompt:
                prompt = clean_string(prompt)
                break
        except Exception as e:
            pass

    return prompt


def delete_old_files():
    while True:
        now = datetime.now()
        cutoff = now - timedelta(minutes=5)
        os.makedirs("./gradio_tmp", exist_ok=True)
        directories = ["./gradio_tmp"]
        for directory in directories:
            for filename in os.listdir(directory):
                file_path = os.path.join(directory, filename)
                if os.path.isfile(file_path):
                    file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_mtime < cutoff:
                        os.remove(file_path)
        time.sleep(600)


threading.Thread(target=delete_old_files, daemon=True).start()


def infer(
    prompt,
    seed,
    randomize_seed,
    width,
    height,
    guidance_scale,
    num_inference_steps,
    num_images,
    progress=gr.Progress(track_tqdm=True),
):
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()

    if randomize_seed:
        seed = random.randint(0, 65536)

    images = pipe(
        prompt=prompt,
        guidance_scale=guidance_scale,
        num_images_per_prompt=num_images,  # ç”Ÿæˆ num_images å¼ å›¾
        num_inference_steps=num_inference_steps,
        width=width,
        height=height,
        generator=torch.Generator().manual_seed(seed),
    ).images  # è·å–ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨

    return images, seed


def update_max_height(width):
            max_height = MAX_PIXELS // width
            return gr.update(maximum=max_height)


def update_max_width(height):
    max_width = MAX_PIXELS // height
    return gr.update(maximum=max_width)


examples = [
    "è¿™æ˜¯ä¸€å¹…å……æ»¡çš®å…‹æ–¯é£æ ¼çš„åŠ¨ç”»æ¸²æŸ“å›¾åƒï¼Œå±•ç°äº†ä¸€åªæ‹ŸäººåŒ–çš„ç²˜åœŸé£æ ¼å°è›‡ã€‚è¿™æ¡å¿«ä¹çš„å°è›‡èº«ç€é­”æœ¯å¸ˆè£…æ‰®ï¼Œå æ®äº†ç”»é¢ä¸‹æ–¹ä¸‰åˆ†ä¹‹ä¸€çš„ä½ç½®ï¼Œæ˜¾å¾—ä¿çš®è€Œç”ŸåŠ¨ã€‚å®ƒçš„å¤´ä¸Šæˆ´ç€ä¸€é¡¶é»‘è‰²ç¾Šæ¯›æè´¨çš„å¤å¤ç¤¼å¸½ï¼Œèº«ä¸Šç©¿ç€ä¸€ä»¶è®¾è®¡ç‹¬ç‰¹çš„çº¢è‰²æ£‰è¢„ï¼Œç™½è‰²çš„æ¯›è¢–å¢æ·»äº†ä¸€æŠ¹æ¸©æš–çš„å¯¹æ¯”ã€‚å°è›‡çš„é³ç‰‡ä¸Šç²¾å¿ƒç»˜åˆ¶äº†é‡‘è‰²æ¢…èŠ±èŠ±çº¹ï¼Œæ˜¾å¾—æ—¢åä¸½åˆä¸å¤±å¯çˆ±ã€‚å®ƒçš„è…¹éƒ¨å’Œè„¸åºå‘ˆç°æ´ç™½ï¼Œä¸çº¢è‰²çš„èº«ä½“å½¢æˆé²œæ˜å¯¹æ¯”ã€‚ è¿™æ¡èœ¿èœ’çš„å°è›‡æ‹¥æœ‰å¯çˆ±çš„å¡‘èƒ¶æ‰‹åŠè´¨æ„Ÿï¼Œä»¿ä½›éšæ—¶ä¼šä»ç”»é¢ä¸­è·ƒç„¶è€Œå‡ºã€‚èƒŒæ™¯æ˜¯ä¸€ç‰‡é²œè‰³çš„çº¢è‰²ï¼Œåœ°é¢ä¸Šæ•£å¸ƒç€å®ç®±ã€é‡‘è›‹å’Œçº¢è‰²ç¯ç¬¼ç­‰è£…é¥°ç‰©ï¼Œè¥é€ å‡ºæµ“åšçš„èŠ‚æ—¥æ°”æ°›ã€‚ç”»é¢çš„ä¸ŠåŠéƒ¨åˆ†ç”¨é‡‘è‰²è¿ä½“å­—ä¹¦å†™ç€ â€œHappy New Yearâ€ï¼Œåº†ç¥æ–°å¹´çš„åˆ°æ¥ï¼ŒåŒæ—¶ä¹Ÿæš—ç¤ºäº†è›‡å¹´çš„åˆ°æ¥ï¼Œä¸ºæ•´å¹…ç”»é¢å¢æ·»äº†ä¸€ä»½èŠ‚æ—¥çš„å–œæ‚¦å’Œç¥¥ç‘ã€‚",
    "åœ¨è¿™å¹…å¦‚æ¢¦ä¼¼å¹»çš„ç”»ä½œä¸­ï¼Œä¸€è¾†ç”±äº‘æœµæ„æˆçš„æ¯›ç»’æ±½è½¦è½»ç›ˆåœ°æ¼‚æµ®åœ¨è”šè“çš„é«˜ç©ºä¹‹ä¸­ã€‚è¿™è¾†æ±½è½¦è®¾è®¡ç‹¬ç‰¹ï¼Œè½¦èº«å®Œå…¨ç”±æ´ç™½ã€è“¬æ¾çš„äº‘æœµç¼–ç»‡è€Œæˆï¼Œæ¯ä¸€å¤„éƒ½æ•£å‘ç€æŸ”è½¯è€Œæ¯›èŒ¸èŒ¸çš„è´¨æ„Ÿã€‚ä»è½¦é¡¶åˆ°è½®èƒï¼Œå†åˆ°å®ƒçš„åœ†æ¶¦è½¦ç¯ï¼Œæ— ä¸€ä¸æ˜¯ç”±ç»†è…»çš„äº‘ä¸æ„æˆï¼Œä»¿ä½›éšæ—¶éƒ½å¯èƒ½éšé£è½»è½»æ‘†åŠ¨ã€‚è½¦çª—ä¹Ÿæ˜¯ç”±é€æ˜çš„äº‘ç‰©è´¨æ„æˆï¼ŒåŒæ ·è¦†ç›–ç€ä¸€å±‚ç»†è½¯çš„ç»’æ¯›ï¼Œè®©äººä¸ç¦æƒ³è¦è§¦æ‘¸ã€‚ è¿™è¾†ç¥å¥‡çš„äº‘æœµæ±½è½¦ä»¿ä½›æ˜¯é­”æ³•ä¸–ç•Œä¸­çš„äº¤é€šå·¥å…·ï¼Œå®ƒæ‚¬æµ®åœ¨å¤•é˜³æ˜ ç…§çš„ç»šä¸½å¤©ç©ºä¹‹ä¸­ï¼Œå‘¨å›´æ˜¯äº”å½©æ–‘æ–“çš„æ™šéœå’Œæ‚ ç„¶é£˜æµ®çš„äº‘å½©ã€‚å¤•é˜³çš„ä½™æ™–æ´’åœ¨äº‘æœµè½¦ä¸Šï¼Œä¸ºå…¶æŸ”è½¯çš„è½®å»“é•€ä¸Šäº†ä¸€å±‚é‡‘è‰²çš„å…‰è¾‰ï¼Œä½¿å¾—æ•´ä¸ªåœºæ™¯æ—¢æ¸©é¦¨åˆç¥ç§˜ï¼Œå¼•äººå…¥èƒœã€‚",
    "A vintage red convertible with gleaming chrome finishes sits attractively under the golden hues of a setting sun, parked on a deserted cobblestone street in a charming old town. The car's polished body reflects the surrounding quaint buildings and the few early evening stars beginning to twinkle in the gentle gradient of the twilight sky. A light breeze teases the few fallen leaves near the car's pristine white-walled tires, which rest casually by the sidewalk, hinting at the leisurely pace of life in this serene setting.",
]
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
            <div>
                <h2 style="font-size: 30px;text-align: center;">CogView4-6B</h2>
            </div>
            <div style="text-align: center;">
                <a href="https://github.com/THUDM/CogView4">ğŸŒ Github</a> |
                <a href="https://arxiv.org/abs/2403.05121">ğŸ“œ arXiv </a>
            </div>
            <div style="text-align: center; font-weight: bold; color: red;">
                âš ï¸ è¯¥æ¼”ç¤ºä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä½“éªŒä½¿ç”¨ã€‚
            </div>
            </div>
        """)

    with gr.Column():
        with gr.Row():
            with gr.Column():
                with gr.Row():
                    prompt = gr.Text(
                        label="Prompt",
                        show_label=False,
                        max_lines=15,
                        placeholder="Enter your prompt",
                        container=False,
                    )
                with gr.Row():
                    enhance = gr.Button("Enhance Prompt (Strongly Suggest)", scale=1)
                    run_button = gr.Button("Run", scale=1)
                with gr.Row():
                    num_images = gr.Number(
                        label="Number of Images",
                        minimum=1,
                        maximum=8,
                        step=1,
                        value=2,
                    )
                    key = gr.Textbox(
                        label="Key",
                        placeholder="Enter your key",
                        type="password",
                        max_lines=1,
                    )
                with gr.Row():
                    seed = gr.Slider(
                        label="Seed",
                        minimum=0,
                        maximum=65536,
                        step=1,
                        value=0,
                    )
                    randomize_seed = gr.Checkbox(label="Randomize seed", value=True)
                with gr.Row():
                    width = gr.Slider(
                        label="Width",
                        minimum=512,
                        maximum=2048,
                        step=32,
                        value=1024,
                    )
                    height = gr.Slider(
                        label="Height",
                        minimum=512,
                        maximum=2048,
                        step=32,
                        value=1024,
                    )
                with gr.Row():
                    guidance_scale = gr.Slider(
                        label="Guidance scale",
                        minimum=0.0,
                        maximum=10.0,
                        step=0.1,
                        value=3.5,
                    )
                    num_inference_steps = gr.Slider(
                        label="Number of inference steps",
                        minimum=10,
                        maximum=100,
                        step=1,
                        value=50,
                    )
            with gr.Column():
                result = gr.Gallery(label="Results", show_label=True)

        MAX_PIXELS = 2**21
        enhance.click(convert_prompt, inputs=[prompt, key], outputs=[prompt])
        width.change(update_max_height, inputs=[width], outputs=[height])
        height.change(update_max_width, inputs=[height], outputs=[width])

        with gr.Column():
            gr.Markdown("### Examples (Enhance prompt finish)")
            for i, ex in enumerate(examples):
                with gr.Row():
                    ex_btn = gr.Button(value=ex, variant="secondary", elem_id=f"ex_btn_{i}", scale=3)
                    ex_img = gr.Image(
                        value=f"inference/img/img_{i + 1}.png",
                        label="Effect",
                        interactive=False,
                        height=130,
                        width=130,
                        scale=1,
                    )
                    ex_btn.click(fn=lambda ex=ex: ex, inputs=[], outputs=prompt)

    gr.on(
        triggers=[run_button.click, prompt.submit],
        fn=infer,
        inputs=[prompt, seed, randomize_seed, width, height, guidance_scale, num_inference_steps, num_images],
        outputs=[result, seed],
    )

demo.queue().launch(inbrowser=True)
